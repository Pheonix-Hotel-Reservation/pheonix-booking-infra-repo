---
# Platform installation playbook for AWS Load Balancer Controller, EBS CSI, Istio, and ArgoCD
- name: Install Platform Components on Kubernetes Cluster
  hosts: master
  become: yes
  vars:
    kubeconfig: /etc/kubernetes/admin.conf
    cluster_name: phoenix-cluster
    aws_region: us-east-1
    aws_account_id: "787169320414"
    vpc_id: "vpc-07722ffa2dab33d2e"

  tasks:
    # ==========================================================================
    # AWS LOAD BALANCER CONTROLLER INSTALLATION
    # ==========================================================================
    - name: Install AWS Load Balancer Controller
      block:
        - name: Add EKS Helm repository
          command: helm repo add eks https://aws.github.io/eks-charts
          environment:
            KUBECONFIG: "{{ kubeconfig }}"
          register: helm_repo_add
          changed_when: "'already exists' not in helm_repo_add.stderr"
          failed_when: false

        - name: Update Helm repositories
          command: helm repo update
          environment:
            KUBECONFIG: "{{ kubeconfig }}"

        - name: Create aws-load-balancer-controller namespace
          command: kubectl create namespace aws-load-balancer-controller
          environment:
            KUBECONFIG: "{{ kubeconfig }}"
          register: ns_create
          failed_when: ns_create.rc != 0 and 'AlreadyExists' not in ns_create.stderr
          changed_when: ns_create.rc == 0

        - name: Create ServiceAccount for AWS Load Balancer Controller
          copy:
            dest: /tmp/aws-lb-controller-sa.yaml
            content: |
              apiVersion: v1
              kind: ServiceAccount
              metadata:
                name: aws-load-balancer-controller
                namespace: aws-load-balancer-controller
                annotations:
                  eks.amazonaws.com/role-arn: arn:aws:iam::{{ aws_account_id }}:role/k8s-node-role

        - name: Apply ServiceAccount
          command: kubectl apply -f /tmp/aws-lb-controller-sa.yaml
          environment:
            KUBECONFIG: "{{ kubeconfig }}"

        - name: Install AWS Load Balancer Controller via Helm
          command: >
            helm upgrade --install aws-load-balancer-controller eks/aws-load-balancer-controller
            -n aws-load-balancer-controller
            --set clusterName={{ cluster_name }}
            --set serviceAccount.create=false
            --set serviceAccount.name=aws-load-balancer-controller
            --set region={{ aws_region }}
            --set vpcId={{ vpc_id }}
          environment:
            KUBECONFIG: "{{ kubeconfig }}"

        - name: Wait for AWS Load Balancer Controller to be ready
          shell: kubectl get pods -n aws-load-balancer-controller -l app.kubernetes.io/name=aws-load-balancer-controller --field-selector=status.phase=Running | grep -c aws-load-balancer-controller || true
          environment:
            KUBECONFIG: "{{ kubeconfig }}"
          register: alb_controller_pods
          until: alb_controller_pods.stdout|int > 0
          retries: 30
          delay: 10

        - name: Display AWS Load Balancer Controller status
          debug:
            msg: "AWS Load Balancer Controller is ready"

    # ==========================================================================
    # EBS CSI DRIVER INSTALLATION
    # ==========================================================================
    - name: Install EBS CSI Driver
      block:
        - name: Add AWS EBS CSI Driver Helm repository
          command: helm repo add aws-ebs-csi-driver https://kubernetes-sigs.github.io/aws-ebs-csi-driver
          environment:
            KUBECONFIG: "{{ kubeconfig }}"
          register: helm_ebs_repo_add
          changed_when: "'already exists' not in helm_ebs_repo_add.stderr"
          failed_when: false

        - name: Update Helm repositories
          command: helm repo update
          environment:
            KUBECONFIG: "{{ kubeconfig }}"

        - name: Create kube-system ServiceAccount for EBS CSI Driver
          copy:
            dest: /tmp/ebs-csi-driver-sa.yaml
            content: |
              apiVersion: v1
              kind: ServiceAccount
              metadata:
                name: ebs-csi-controller-sa
                namespace: kube-system
                annotations:
                  eks.amazonaws.com/role-arn: arn:aws:iam::{{ aws_account_id }}:role/k8s-node-role

        - name: Apply EBS CSI ServiceAccount
          command: kubectl apply -f /tmp/ebs-csi-driver-sa.yaml
          environment:
            KUBECONFIG: "{{ kubeconfig }}"

        - name: Install EBS CSI Driver via Helm
          command: >
            helm upgrade --install aws-ebs-csi-driver aws-ebs-csi-driver/aws-ebs-csi-driver
            -n kube-system
            --set controller.serviceAccount.create=false
            --set controller.serviceAccount.name=ebs-csi-controller-sa
          environment:
            KUBECONFIG: "{{ kubeconfig }}"

        - name: Wait for EBS CSI Controller to be ready
          shell: kubectl get pods -n kube-system -l app=ebs-csi-controller --field-selector=status.phase=Running | grep -c ebs-csi-controller || true
          environment:
            KUBECONFIG: "{{ kubeconfig }}"
          register: ebs_controller_pods
          until: ebs_controller_pods.stdout|int > 0
          retries: 30
          delay: 10

        - name: Create default GP3 StorageClass
          copy:
            dest: /tmp/storageclass-gp3.yaml
            content: |
              apiVersion: storage.k8s.io/v1
              kind: StorageClass
              metadata:
                name: gp3
                annotations:
                  storageclass.kubernetes.io/is-default-class: "true"
              provisioner: ebs.csi.aws.com
              parameters:
                type: gp3
                fsType: ext4
                encrypted: "true"
              volumeBindingMode: WaitForFirstConsumer
              allowVolumeExpansion: true

        - name: Apply StorageClass
          command: kubectl apply -f /tmp/storageclass-gp3.yaml
          environment:
            KUBECONFIG: "{{ kubeconfig }}"

        - name: Display EBS CSI Driver status
          debug:
            msg: "EBS CSI Driver is ready with default StorageClass 'gp3'"

    # ==========================================================================
    # ISTIO INSTALLATION
    # ==========================================================================
    - name: Install Istio
      block:
        - name: Download Istio 1.20.2
          get_url:
            url: https://github.com/istio/istio/releases/download/1.20.2/istio-1.20.2-linux-amd64.tar.gz
            dest: /tmp/istio-1.20.2-linux-amd64.tar.gz
            mode: '0644'

        - name: Extract Istio
          unarchive:
            src: /tmp/istio-1.20.2-linux-amd64.tar.gz
            dest: /tmp/
            remote_src: yes
            creates: /tmp/istio-1.20.2

        - name: Copy istioctl to /usr/local/bin
          copy:
            src: /tmp/istio-1.20.2/bin/istioctl
            dest: /usr/local/bin/istioctl
            mode: '0755'
            remote_src: yes

        - name: Install Istio base
          command: /usr/local/bin/istioctl install --set profile=default -y
          environment:
            KUBECONFIG: "{{ kubeconfig }}"

        - name: Create istio-ingress namespace
          command: kubectl create namespace istio-ingress
          environment:
            KUBECONFIG: "{{ kubeconfig }}"
          register: istio_ns_create
          failed_when: istio_ns_create.rc != 0 and 'AlreadyExists' not in istio_ns_create.stderr
          changed_when: istio_ns_create.rc == 0

        - name: Label istio-ingress namespace for injection
          command: kubectl label namespace istio-ingress istio-injection=enabled --overwrite
          environment:
            KUBECONFIG: "{{ kubeconfig }}"

        - name: Wait for Istio control plane to be ready
          shell: kubectl get pods -n istio-system -l app=istiod --field-selector=status.phase=Running | grep -c istiod || true
          environment:
            KUBECONFIG: "{{ kubeconfig }}"
          register: istiod_pods
          until: istiod_pods.stdout|int > 0
          retries: 30
          delay: 10

        - name: Display Istio status
          debug:
            msg: "Istio control plane is ready"

    # ==========================================================================
    # ARGOCD INSTALLATION
    # ==========================================================================
    - name: Install ArgoCD
      block:
        - name: Create argocd namespace
          command: kubectl create namespace argocd
          environment:
            KUBECONFIG: "{{ kubeconfig }}"
          register: argocd_ns_create
          failed_when: argocd_ns_create.rc != 0 and 'AlreadyExists' not in argocd_ns_create.stderr
          changed_when: argocd_ns_create.rc == 0

        - name: Install ArgoCD
          command: kubectl apply -n argocd -f https://raw.githubusercontent.com/argoproj/argo-cd/stable/manifests/install.yaml
          environment:
            KUBECONFIG: "{{ kubeconfig }}"

        - name: Wait for ArgoCD server to be ready
          shell: kubectl get pods -n argocd -l app.kubernetes.io/name=argocd-server --field-selector=status.phase=Running | grep -c argocd-server || true
          environment:
            KUBECONFIG: "{{ kubeconfig }}"
          register: argocd_pods
          until: argocd_pods.stdout|int > 0
          retries: 60
          delay: 10

        - name: Patch ArgoCD server service to use LoadBalancer
          command: kubectl patch svc argocd-server -n argocd -p '{"spec":{"type":"LoadBalancer"}}'
          environment:
            KUBECONFIG: "{{ kubeconfig }}"

        - name: Wait for LoadBalancer to be provisioned
          shell: kubectl get svc argocd-server -n argocd -o jsonpath='{.status.loadBalancer.ingress[0].hostname}' 2>/dev/null || echo ""
          environment:
            KUBECONFIG: "{{ kubeconfig }}"
          register: argocd_lb
          until: argocd_lb.stdout != ""
          retries: 30
          delay: 10

        - name: Get ArgoCD initial admin password
          shell: kubectl -n argocd get secret argocd-initial-admin-secret -o jsonpath="{.data.password}" | base64 -d
          environment:
            KUBECONFIG: "{{ kubeconfig }}"
          register: argocd_password
          changed_when: false

        - name: Display ArgoCD access information
          debug:
            msg:
              - "ArgoCD is ready!"
              - "URL: https://{{ argocd_lb.stdout }}"
              - "Username: admin"
              - "Password: {{ argocd_password.stdout }}"

    # ==========================================================================
    # FINAL STATUS
    # ==========================================================================
    - name: Display final platform status
      debug:
        msg:
          - "Platform installation complete!"
          - "AWS Load Balancer Controller: Installed"
          - "EBS CSI Driver: Installed (default StorageClass: gp3)"
          - "Istio: Installed (version 1.20.2)"
          - "ArgoCD: Installed and accessible at https://{{ argocd_lb.stdout }}"
