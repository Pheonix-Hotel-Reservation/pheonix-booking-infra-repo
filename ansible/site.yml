---
# Main playbook for Kubernetes cluster setup with AWS Cloud Controller Manager
- name: Configure all nodes with common setup
  hosts: all
  become: yes
  roles:
    - common

- name: Initialize Kubernetes master with CCM support
  hosts: master
  become: yes
  roles:
    - master

- name: Join worker nodes to the cluster
  hosts: workers
  become: yes
  roles:
    - worker

- name: Verify AWS Cloud Provider Integration
  hosts: master
  become: yes
  tasks:
    - name: Wait for all nodes to have provider IDs
      shell: |
        TOTAL=$(kubectl get nodes --no-headers | wc -l)
        WITH_PROVIDER=$(kubectl get nodes -o jsonpath='{range .items[*]}{.spec.providerID}{"\n"}{end}' | grep -c "^aws://" || echo "0")
        echo "$WITH_PROVIDER/$TOTAL"
      environment:
        KUBECONFIG: /etc/kubernetes/admin.conf
      register: provider_id_status
      until: provider_id_status.stdout is match("^[0-9]+/[0-9]+$") and provider_id_status.stdout.split('/')[0] == provider_id_status.stdout.split('/')[1]
      retries: 60
      delay: 10

    - name: Display all nodes with provider IDs
      shell: kubectl get nodes -o custom-columns=NAME:.metadata.name,PROVIDER:.spec.providerID,STATUS:.status.conditions[-1].type
      environment:
        KUBECONFIG: /etc/kubernetes/admin.conf
      register: nodes_status

    - name: Show final cluster status
      debug:
        msg: "{{ nodes_status.stdout_lines }}"

    - name: Final verification message
      debug:
        msg: "âœ… SUCCESS! All {{ provider_id_status.stdout.split('/')[1] }} nodes have AWS provider IDs and are Ready!"
